{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to the NovaScope Exemplary Downstream Analysis (NEDA) Documentation","text":""},{"location":"#introduction","title":"Introduction","text":"<p>This document serves as a guide for exemplary downstream analysis of spatial transcriptomics data generated from NovaScope. The main functionalities include:</p> <p>1) Pixel-level Analysis:     This feature enables the identification of spatial factors at a pixel-level resolution using a hexagon-indexed spatial digital gene expression matrix (SGE).</p> <p>2) Cell Segmentation-based Analysis:      This feature facilitates the aggregation of spatial transcriptomics data at the cellular level based on histology files and supports the analysis of cell type clusters using the cell-indexed SGE.</p>"},{"location":"#references","title":"References","text":"<p>For additional information, please refer to the following publications:</p> <ul> <li>NovaScope Protocol Preprint </li> <li>NovaScope</li> <li>FICTURE Preprint</li> </ul>"},{"location":"analysis/cell_idx/intro/","title":"Cell Segmentation-based Analysis","text":"<p>This is an example to illustrate aggregating the spatial transcriptomic data from NovaScope at the cell level, and clustering cells using Seurat build-in graph-based clustering approach. </p> <p> Figure 2: A Brief Overview of the Inputs, Outputs, and Process Steps for Cell Segmentation-based Analysis. SGE: spatial digital gene expression matrix; UMAP: Uniform Manifold Approximation and Projection.</p>"},{"location":"analysis/cell_idx/intro/#step-by-step-procedure","title":"Step-by-Step Procedure","text":"<p>Before beginning the analysis, ensure that NEDA and its dependencies are installed in your computing environment. Follow these steps as outlined:</p> <ol> <li> <p>Create a cell-indexed spatial digital gene expression matrix. This step requires the users manuually perform histology-based cell segmentation outside of NEDA using methods such as Watershed and Cellpose. </p> </li> <li> <p>Apply Seurat to identify cell type clusters for those staining-based segmented cells.</p> </li> </ol>"},{"location":"analysis/cell_idx/prepare_data/","title":"Preparing Input Dataset","text":""},{"location":"analysis/cell_idx/prepare_data/#mandatory-input-files","title":"Mandatory Input Files:","text":"<p>The following required input files can be generated using NovaScope.</p> <ul> <li> <p>A referenced Histology File:   The input histology file should be a referenced histology file GeoTIFF format, which facilitates the coordinate transformation between the input Spatial Gene Expression (SGE) matrix and the histology image. This means that the histology file must be aligned with the input SGE matrix and match its dimensions. For more details, refer to this link.</p> </li> <li> <p>Transcript-Indexed Spatial Digital Gene Expression Matrix (SGE) in 10x genomics Format:   A transcript-indexed SGE in 10x Genomics format contains all available genomic feature. Each SGE dataset is composed of <code>features.tsv.gz</code>, <code>barcodes.tsv.gz</code>, and <code>matrix.mtx.gz</code>. Details are provided here.</p> </li> </ul>"},{"location":"analysis/cell_idx/prepare_data/#example-datasets","title":"Example Datasets","text":"<p>NEDA provides two example datasets for this Cell Segmentation-based Analysis, including the Shallow Liver Section Dataset and Deep Liver Section Dataset. Each dataset contains the input transcript-indexed SGE and histology files. We also provide the the cell segment mask from Cellposeas well as the black and white boundary TIF image from Watershed.</p> <p>Details on these datasets and download instructions are available in Accessing Example Datasets.</p>"},{"location":"analysis/cell_idx/step1-cell_SGE/","title":"Step1. Prepare Cell-indexed Spatial Digital Gene Expression Matrix","text":""},{"location":"analysis/cell_idx/step1-cell_SGE/#set-up-computing-environment","title":"Set Up Computing Environment","text":"<p>Ensure that your computing environment is properly configured before each step.</p> <pre><code>## Load modules, if applicable.\n## For non-HPC user, use `export` to set the paths for following softwares, e.g., `export R=&lt;path_to_R&gt;`.\nmodule load R/4.2.0                                \n\n## Activate Python environment\n## If your Python environment was not set up using venv, replace the following lines with the appropriate commands to activate the environment.\npy_env=\"&lt;path_to_python_env&gt;\"                           ## replace &lt;path_to_python_env&gt; with the path to the python environment\nsource ${py_env}/bin/activate\nexport python=${py_env}/bin/python\n\n## Define NEDA\nneda=/path/to/the/NEDA/repository  # Replace with the path to the NEDA repository\n\n## Specify directories for input and output files\nsge_dir=/path/to/the/sge                                ## Replace with the path to the directory containing input SGE\n\n## Specify paths for segmentation files (depends on the segmentation technique used)\nwatershed_tiff=/path/to/watershed/segmentation/tiff     ## (For Watershed) Replace with the path to the black-and-white cell segmentation TIFF image\ncellpose_npy=/path/to/cellpose/segmentation/npg         ## (For Cellpose) Replace with the path to the Cellpose output npy file\n\n# Specify output directory and prefix\noutput_dir=/path/to/the/output/directory                ## Replace with your output directory\nprefix=&lt;output_prefix&gt;                                  ## Replace with your output prefix, e.g., watershed\n</code></pre>"},{"location":"analysis/cell_idx/step1-cell_SGE/#step-11-prepare-histology-based-cell-segmentation-mask-matrix","title":"Step 1.1 Prepare Histology-based Cell Segmentation Mask Matrix","text":"<p>To construct a cell-indexed spatial digital gene expression matrix (SGE), begin by executing histology-based cell segmentation using external methodologies, such as Watershed or Cellpose. Details for performing histology-based cell segmentation using Watershed and Cellpose are provided in the NovaScope Protocol paper. </p> <p>Note</p> <p>Irrespective of the segmentation technique used, ensure that the input histology image is aligned with the input SGE. </p> <p>This alignment involves referencing and resizing the histology image to match the SGE coordinates and dimensions, which can be accomplished by Rule <code>historef</code> in NovaScope.</p>"},{"location":"analysis/cell_idx/step1-cell_SGE/#watershed","title":"Watershed","text":"<p>Watershed outputs a black-and-white cell segmentation TIFF image (please see an example below) where white areas represent cell segments and black areas are non-tissue regions or cell boundaries. NEDA provides <code>make_segmask.py</code> to convert this image into a segmentation mask matrix in <code>NumPy</code> array format.</p> <p>Input &amp; Output <pre><code># Input: \n$watershed_tiff                                         ## a user-defined black-and-white cell segmentation TIFF image\n\n# Output: \n${output_dir}/${prefix}_areas.png\n${output_dir}/${prefix}_seg.npy                         ## segmentation mask matrix in the NumPy array format\n</code></pre></p> <p>Commands: <pre><code>python $neda/scripts/make_segmask.py \\\n   --input ${watershed_tiff} \\\n   --outpref ${output_dir}/${prefix}\n</code></pre></p> <p>Examples:</p> <p> Figure 3: A black-and-white cell segmentation TIFF image from Watershed. </p>"},{"location":"analysis/cell_idx/step1-cell_SGE/#cellpose","title":"Cellpose","text":"<p>Cellpose produces an <code>npy</code> file that serves as the segmentation mask matrix in <code>NumPy</code> array format. No additional action is required with NEDA.</p>"},{"location":"analysis/cell_idx/step1-cell_SGE/#step12-create-cell-indexed-spatial-digital-gene-expression-matrix","title":"Step1.2 Create cell-indexed spatial digital gene expression matrix","text":"<p>Use the histology-based cell segmentation mask matrix file from Step1.1 to aggregate spatial transcriptomic data at the cellular level. NEDA\u2019s <code>make_sge_from_npy.py</code> script is utilized here. Note that the npy file from Watershed and Cellpose differs, so the script requires specifying the <code>--approach</code>. This step creates a cell-indexed SGE in 10x genomics format.</p>"},{"location":"analysis/cell_idx/step1-cell_SGE/#watershed_1","title":"Watershed","text":"<p>Input &amp; Output <pre><code># Input: \n$sge_dir                                            ## directory containing barcodes.tsv.gz, features.tsv.gz, matrix.mtx.gz\n${output_dir}/${prefix}_seg.npy                     ## segmentation mask matrix in NumPy array format\n\n# Output: \n${output_dir}/${prefix}/barcodes.tsv.gz            \n${output_dir}/${prefix}/features.tsv.gz \n${output_dir}/${prefix}/matrix.mtx.gz\n</code></pre></p> <p>Commands: <pre><code>python ${neda}/scripts/make_sge_from_npy.py \\\n   --input ${output_dir}/${prefix}_seg.npy \\\n   --approach Watershed \\\n   --sge_dir ${sge_dir} \\\n   --output_dir ${output_dir}/${prefix}\n</code></pre></p>"},{"location":"analysis/cell_idx/step1-cell_SGE/#cellpose_1","title":"Cellpose","text":"<p>Input &amp; Output <pre><code># Input: \n$sge_dir                                            ## directory containing barcodes.tsv.gz, features.tsv.gz, matrix.mtx.gz\n$cellpose_npy                                       ## user-defined Cellpose output segmentation mask matrix in NumPy array format\n\n# Output: \n${output_dir}/${prefix}/barcodes.tsv.gz            \n${output_dir}/${prefix}/features.tsv.gz \n${output_dir}/${prefix}/matrix.mtx.gz\n</code></pre></p> <p>Commands: <pre><code>python ${neda}/scripts/make_sge_from_npy.py \\\n   --input ${cellpose_npy} \\\n   --approach Cellpose \\\n   --sge_dir ${sge_dir} \\\n   --output_dir ${output_dir}/${prefix}\n</code></pre></p>"},{"location":"analysis/cell_idx/step2-Seurat-clustering/","title":"Step 2. Inferring Cell Type Factors using Seurat","text":"<p>This example demonstrates how to infer cell type factors from a cell-indexed SGE using <code>Seurat</code>.</p> <p>The step script starts with the removal of mitochondrial and hypothetical genes and the filtering of hexagons based on <code>nFeature_RNA_cutoff</code> X Y ranges, when applied. Subsequently, it applies sctransform normalization followed by dimensionality reduction through Principal Component Analysis (PCA) and Uniform Manifold Approximation and Projection (UMAP) embedding.</p> <p>Next, the step script employs <code>FindClusters</code> segregate hexagons into clusters utilizing a shared nearest neighbor (SNN) modularity optimization-based clustering algorithm. The argument <code>resolution</code> in <code>FindClusters</code> determines the \"granularity\" of clusters, i.e., a higher resolution value yields more clusters. Thus, this step will examine the performance of a range of <code>resolutions</code>, including 0.25, 0.5, 0.75, 1, 1.25, 1.5, and 1.75. For each specified resolution, the script generates an UMAP for dimensionality reduction, a spatial plot to visualize the clusters and their spatial arrangement, and a Differential Expression (DE) file, detailing marker genes identified for each cluster.</p> <p>Additionally, this step generates a metadata file containing information on the cluster assignment for each hexagon, and an RDS (R Data Serialization) file that stores the complete Seurat object with all the compiled data.</p> <p>Input &amp; Output <pre><code># Input: \n${output_dir}/${prefix}/barcodes.tsv.gz                                          # the cell-indexed SGE from step1\n${output_dir}/${prefix}/features.tsv.gz \n${output_dir}/${prefix}/matrix.mtx.gz\n\n# Output: \n${output_dir}/${prefix}_cutoff${nFeature_RNA_cutoff}_metadata.csv                # a metadata file\n${output_dir}/${prefix}_cutoff${nFeature_RNA_cutoff}_SCT.RDS                     # an RDS file\n${output_dir}/${prefix}_cutoff${nFeature_RNA_cutoff}_res${res}_DE.csv            # for each resolution (`$res`) including 0.25, 0.5, 0.75, 1, 1.25, 1.5, and 1.75\n${output_dir}/${prefix}_cutoff${nFeature_RNA_cutoff}_res${res}_DimSpatial.png    # for each resolution (`$res`) including 0.25, 0.5, 0.75, 1, 1.25, 1.5, and 1.75\n</code></pre></p> <p>Parameters:</p> <ul> <li><code>--X_col</code>: Specify which part of the hexagon ID corresponds to the X coordinate. For instance, in our example dataset, the hexagon ID is formatted as <code>{X}_{Y}</code>, i.e., the X coordinate is the first component. In this case, <code>--X_col</code> set this argument to 1.  Default: 3.</li> <li><code>--Y_col</code>: Specify which part of the hexagon ID corresponds to the Y coordinate. As the Y coordinate is the second component in the example case, it should set to 2.  Default: 4.</li> <li><code>--nFeature_RNA_cutoff</code>: Cutoff value for filtering hexagons by nFeature_RNA. Since this cell-indexed SGE is derived from histology files, <code>nFeature_RNA_cutoff</code> is set to be 0.</li> </ul> <p>Commands: <pre><code>Rscript ${neda}/scripts/seurat_analysis.R \\\n    --input_dir ${output_dir}/${prefix} \\\n    --output_dir ${output_dir}/${prefix}/Seurat \\\n    --unit_id ${prefix} \\\n    --X_col 1 \\\n    --Y_col 2 \\\n    --nFeature_RNA_cutoff 0 \n</code></pre></p>"},{"location":"analysis/hex_idx/intro/","title":"Pixel-level Analysis","text":"<p>This section provides an example of how to identify spatial factors at pixel-level resolution in spatial transcriptomics data, which is generated by NovaScope. NEDA currently offers two analytical strategies:</p> <p>1) Latent Dirichlet Allocation (LDA) + FICTURE: This strategy utilizes Latent Dirichlet Allocation (LDA) to identify spatial factors. Subsequently, FICTURE is employed to map these identified factors onto a histological space with pixel-level resolution.</p> <p>2) Seurat + FICTURE: In this strategy, multi-dimensional clustering via Seurat is applied to explore cell type clusters. These clusters are then projected into a histological space, achieving pixel-level resolution through the use of FICTURE.</p> <p> Figure 1: A Brief Overview of the Inputs, Outputs, and Process Steps for Pixel-level Analysis. </p>"},{"location":"analysis/hex_idx/intro/#step-by-step-procedure","title":"Step-by-Step Procedure","text":"<p>Before beginning the analysis, ensure that NEDA and its dependencies are installed in your computing environment. Follow these steps as outlined:</p> <ol> <li> <p>Prepare your input dataset and its corresponding input configuration file.</p> </li> <li> <p>Set up your computing environment, preprocess the spatial transcriptomic data, and create minibatches for subsequent analysis.</p> </li> <li> <p>Choose the analytical strategy that best suits your project, either LDA or Seurat, to yield clusters or factors from your dataset.</p> </li> <li> <p>Transform and decode these clusters or factors on your input data at pixel-level resolution.</p> </li> </ol> <p>Detailed instructions for each step are available on the corresponding pages, including:</p> <ul> <li>The purpose of each step;</li> <li>The execution command;</li> <li>Necessary input and output files;</li> <li>Definitions of auxiliary parameters, as outlined in the scripts for each step.</li> </ul>"},{"location":"analysis/hex_idx/job_config/","title":"Preparing the Input Configuration File","text":"<p>Given the amount of the paths and parameters, NEDA employs a text file as an input configuration file, which contains parameters and dataset paths. We offer separate example configuration files for LDA+FICTURE analysis and Seurat+FICTURE analysis. </p> <p>Below only include FICTURE's essential parameters, while certain steps might need auxiliary parameters. In such cases, NEDA employs FICTURE's recommended defaults for these extra settings, wherever applicable. Should you wish to customize these auxiliary parameters beyond the defaults, please proceed with caution as it involves risk. For detailed information on modifying auxiliary parameters, kindly refer to the <code>AUXILIARY PARAMS</code> section in the script for each respective step and the guidance of FICTURE.</p> <pre><code>#=========================\n# Mandatory Fields\n#=========================\n## Input files\ntranscripts=/path/to/the/transcripts/file                           ## Path to the FICTURE-compatible spatial digital gene expression matrix (SGE), whose naming convention in NovaScope is *.transcripts.tsv.gz.\ninput_features=/path/to/the/clean/feature/file                       ## NovaScope name convention is *.feature.clean.tsv.gz\nmajor_axis=&lt;X_or_Y&gt;                                                 ## Typically, the major axis is the axis with a greater length. Options: \"X\", \"Y\". For instance, in the minimal test run dataset, the major axis is Y, whereas it is X in the shallow and deep liver datasets.\n\n## Input file Only required for Seurat+FICTURE analysis\nhexagon_sge_dir=/path/to/the/hexagon/indexed/sge/directory          ## (Seurat-only) Specify the directory with hexagon-indexed SGE, i.e., SGE with pixels segmented into hexagonal units, in the 10x genomics format. This directory should have the following three files: features.tsv.gz, barcodes.tsv.gz, and matrix.mtx.gz.\n\n## Output \noutput_dir=/path/to/the/output/directory/                           ## Directory for output files: LDA results will be saved in ${output_dir}/LDA, and Seurat results wil be in ${output_dir}/Seurat.\"\nprefix=&lt;prefix_of_output_files&gt;                                     ## Prefix for output files. The output files will be named using both this prefix and the following analytical parameters.\n\n## Analysis model\ntrain_model=&lt;model_option&gt;                                          ## Define the analytical strategy. Options: \"LDA\", \"Seurat\".\n\n## Analysis param\nsolo_feature=&lt;solo_feature&gt;                                         ## The soloFeatures selection. Options: \"gn\": Gene; \"gt\": GeneFull. See details at https://github.com/alexdobin/STAR/blob/master/docs/STARsolo.md.\ntrain_width=&lt;train_width&gt;                                           ## The side length of the hexagon (in micrometers), e.g., 18.\nfit_width=&lt;projection_width&gt;                                        ## Projection width, suggest to use one the same as the train width, e.g., 18.\nanchor_dist=&lt;archor_distance&gt;                                       ## Anchor point distance (in micrometers), e.g., 4.\n\n## Analysis strategy-specific params\nnfactor=&lt;number_of_factors&gt;                                         ## (LDA-only) Number of factors, e.g., 12. For the 'Seurat + FICTURE' analysis, remove it when preparing the configuration file; nf will be defined after clustering.\ntrain_n_epoch=&lt;number_of_epoch&gt;                                     ## (LDA-only) Epochs for LDA training, e.g., 3. For \"Seurat+FICTURE\" analysis, use \"NA\" or remove it.\nres_of_interest=1                                                   ## (Seurat-only) After examining the clustering results across all resolution settings, identify the optimal results for FICTURE projection by specifying the resolution for these results here.\n\n#=========================\n# Optional Fields\n#=========================\n#threads=&lt;number_of_cpus&gt;                                           ## (Optional) A integer to indicate how many CPUs will be applied. If absent, 1 thread will be applied.\n#seed=&lt;an_integer&gt;                                                  ## (Optional) A seed (integer, e.g., 2024030700) for reproducibility. This applies in the LDA factorization and choosing color maps. If omitted, a random seed will be utilized.\n</code></pre>"},{"location":"analysis/hex_idx/prepare_data/","title":"Preparing Input Dataset","text":"<p>While the input spatial transcriptomics data varies between strategies, both can be generated using NovaScope. </p>"},{"location":"analysis/hex_idx/prepare_data/#mandatory-input-files","title":"Mandatory Input Files:","text":"<p>Regardless of the chosen strategy, the following files are essential and can be prepared using the Rule <code>sdgeAR_reformat</code> in NovaScope:</p> <ul> <li>FICTURE-Compatible Spatial Digital Gene Expression (SGE) Matrix:   This is a spatial transcriptomic data in a FICTURE-compatible format. It contains all informations including the barcode information, features information, and count for each genomic feature. The data format, and naming convention are provided here.</li> <li>Tab-Delimited Feature File:   This file should contain information such as gene ID, gene name, and counts for each genomic feature. It is advisable to use the gene-filtered feature file from NovaScope (i.e., <code>*.feature.clean.tsv.gz</code>). Further details are available here.</li> </ul>"},{"location":"analysis/hex_idx/prepare_data/#seurat-only-input-files","title":"Seurat-Only Input Files","text":"<p>When opting for the <code>Seurat+FICTURE</code> strategy, the following specific file is required:</p> <ul> <li>Hexagon-Indexed SGE in 10x genomics Format: This SGE is created by segmenting pixels into hexagonal units, the size of which is defined by the user. The format aligns with the 10x genomics standards. More details are provided here.</li> </ul>"},{"location":"analysis/hex_idx/prepare_data/#example-datasets","title":"Example Datasets","text":"<p>Alternatively, NEDA offers three example datasets, each suitable for input in spatial transcriptomic analysis within NEDA. For detailed information on these datasets and instructions on how to download them, see Accessing Example Datasets.</p>"},{"location":"analysis/hex_idx/step1-preprocess/","title":"Step 1. Preprocessing","text":""},{"location":"analysis/hex_idx/step1-preprocess/#set-up-computing-environment","title":"Set Up Computing Environment","text":"<p>Please make sure set up the computing environment before each step. </p> <pre><code>## Load modules, if applicable.\n## For non-HPC user, use `export` to set the paths for following softwares, e.g., `export samtools=&lt;path_to_samtools&gt;`.\nmodule load Bioinformatics                          ## In this example, samtools is part of the Bioinformatics module system, requiring the Bioinformatics module to be loaded before accessing the specific program.\nmodule load samtools\nmodule load R/4.2.0                                ## R is only required for Seurat+FICTURE analysis.\n\n## Activate Python environment\n## If your Python environment was not set up using venv, replace the following lines with the appropriate commands to activate the environment.\npy_env=\"&lt;path_to_python_env&gt;\"                       ## replace &lt;path_to_python_env&gt; with the path to the python environment\nsource ${py_env}/bin/activate\nexport python=${py_env}/bin/python\n\n## Define NEDA\nneda_dir=\"&lt;path_to_the_NEDA_repository&gt;\"            ## replace &lt;path_to_the_NEDA_repository&gt; with the path to the NovaScope-exemplary-downstream-analysis repository\n\n## Specify the input configure file\ninput_configfile=\"&lt;path_to_input_data_and_params&gt;\"  ## replace &lt;path_to_input_data_and_params&gt; with the path to the config_job file, e.g., ${neda_dir}/config_job/input_config_lda.txt\n</code></pre>"},{"location":"analysis/hex_idx/step1-preprocess/#step-11-filtering","title":"Step 1.1 Filtering","text":"<p>Filter the FICTURE-compatible SGE by the density and create a strict boundary file based on the density of transcripts.</p> <p>Input &amp; Output <pre><code># Input: \n$transcripts                                        # User-defined input FICTURE-compatible SGE file\n$input_features                                      # User-defined input filtered feature file\n\n#Output: \n${output_dir}/${prefix}.transcripts_filtered.tsv.gz\n${output_dir}/${prefix}.boundary.strict.geojson\n${output_dir}/${prefix}.coordinate_minmax.tsv\n</code></pre></p> <p>Commands: <pre><code>$neda_dir/steps/step1.1-filter-transcripts $input_configfile\n</code></pre></p>"},{"location":"analysis/hex_idx/step1-preprocess/#step-12-creating-minimatch","title":"Step 1.2 Creating Minimatch","text":"<p>Assigning minibatch label, and reordering the data based on the major axis so that they are locally contiguous. This output file will be applied in the step of projecting the factors into the pixel-level dataset using FICTURE.</p> <p>Input &amp; Output <pre><code>#Input: \n${output_dir}/${prefix}.transcripts_filtered.tsv.gz\n\n#Output: \n${output_dir}/${prefix}.batched.matrix.tsv.gz\n</code></pre></p> <p>Commands: <pre><code>$neda_dir/steps/step1.2-create-minibatch.sh $input_configfile\n</code></pre></p>"},{"location":"analysis/hex_idx/step2a-LDA/","title":"Step 2a. Infer Cell Type Factors using Latent Dirichlet Allocation (LDA).","text":"<p>This example illustrates infering cell type factors using Latent Dirichlet Allocation (LDA). </p> <p>Prefix:</p> <p>To clarify the input and output filenames, we utilize prefixes in this documentation. Below, we illustrate how these prefixes are defined. Those prefixes are automatically defined by the script; users do NOT need to manually define them. </p> <pre><code>hexagon_prefix=\"${prefix}.hexagon.${sf}.d_${tw}\"\ntrain_prefix=\"${prefix}.${sf}.nF${nf}.d_${tw}.s_${ep}\"\n</code></pre> <ul> <li>Details on variables used in above prefixes are in the Job Configuration.</li> </ul>"},{"location":"analysis/hex_idx/step2a-LDA/#step-2a1-create-hexagonal-spatial-gene-expression-sge-matrix","title":"Step 2a.1 Create Hexagonal Spatial Gene Expression (SGE) matrix","text":"<p>Given a specified size of hexagons, segment the raw spatial gene expression (SGE) matrix into hexagonal SGE.</p> <p>Input &amp; Output <pre><code># Input:\n${output_dir}/${prefix}.transcripts_filtered.tsv.gz\n${output_dir}/${prefix}.boundary.strict.geojson\n\n# Output: \n${output_dir}/${train_model}/${hexagon_prefix}.tsv.gz\n</code></pre></p> <p>Commands: <pre><code>$neda_dir/steps/step2a.1-create-hexagons.sh $input_configfile\n</code></pre></p>"},{"location":"analysis/hex_idx/step2a-LDA/#step-2a2-lda-factorization","title":"Step 2a.2 LDA Factorization","text":"<p>An unsupervised learning of cell type factors using LDA.</p> <p>Input &amp; Output: <pre><code># Input:\n${output_dir}/${prefix}.feature.clean.tsv.gz\n${output_dir}/${train_model}/${hexagon_prefix}.tsv.gz\n\n# Output: \n${output_dir}/${train_model}/${train_prefix}.model.p\n${output_dir}/${train_model}/${train_prefix}.model_matrix.tsv.gz\n${output_dir}/${train_model}/${train_prefix}.fit_result.tsv.gz\n${output_dir}/${train_model}/${train_prefix}.posterior.count.tsv.gz\n${output_dir}/${train_model}/${train_prefix}.coherence.tsv\n${output_dir}/${train_model}/${train_prefix}.model_selection_candidates.p\n</code></pre></p> <p>Commands: <pre><code>$neda_dir/steps/step2a.2-LDA-factorization.sh $input_configfile\n</code></pre></p>"},{"location":"analysis/hex_idx/step2a-LDA/#step-2a3-creating-marker-gene-reports","title":"Step 2a.3 Creating Marker Gene Reports","text":"<p>This step includes: generating a color table, identifying marker genes for each factor, and creating a report html file, which summarizes individual factors and marker genes.</p> <p>Input &amp; Output: <pre><code># Input:\n${output_dir}/${train_model}/${train_prefix}.fit_result.tsv.gz\n${output_dir}/${train_model}/${train_prefix}.posterior.count.tsv.gz\n\n# Output: \n${output_dir}/${train_model}/${train_prefix}.color.tsv\n${output_dir}/${train_model}/${train_prefix}.bulk_chisq.tsv\n${output_dir}/${train_model}/${train_prefix}.factor.info.html\n</code></pre></p> <p>Commands: <pre><code>$neda_dir/steps/step2a.3-LDA-factorization-report.sh $input_configfile\n</code></pre></p>"},{"location":"analysis/hex_idx/step2b-seurat/","title":"Step 2b. Inferring Cell Type Factors using Seurat","text":"<p>This example illustrates infering cell type factors using Seurat. This process contains two stops that require manual evaluation, including one at step 2b.2 and the other at step 2b.4. </p> <p>Prefix:</p> <p>This documentation uses the following prefixes to illustrate input and output filenames, which are automatically assigned by the script. </p> <pre><code>hexagon_prefix=\"${prefix}.hexagon.${sf}.d_${tw}\"\ntrain_prefix=\"${prefix}.${sf}.nF${nf}.d_${tw}.s_${ep}\"    \n</code></pre> <ul> <li>The <code>nf</code> will be determined in step 2b.5.</li> <li>Details on variables used in above prefixes are in the Job Configuration.</li> </ul>"},{"location":"analysis/hex_idx/step2b-seurat/#step-2b1-data-evaluation","title":"Step 2b.1 Data Evaluation","text":"<p>This step applies the 'Seurat_analysis.R' script in test mode for evaluation, which includes:</p> <ul> <li>Assessing counts of mitochondrial and hypothetical genes,</li> <li>Examining the distribution of the number of spatial barcodes per hexagon (nCount_RNA) and the number of genes detected per hexagon (Nfeature_RNA),</li> <li>Filtering the SGE with various nFeature_RNA thresholds \u2014 50, 100, 200, 300, 400, 500, 750, and 1000 \u2014 and creating density plots to assess each threshold's efficacy</li> </ul> <p>Input &amp; Output <pre><code># Input:\n${hexagon_sge_dir}/features.tsv.gz\n${hexagon_sge_dir}/barcodes.tsv.gz\n${hexagon_sge_dir}/matrix.mtx.gz\n\n# Output: \n${output_dir}/${train_model}/Ncount_Nfeature_vln.png\n${output_dir}/${train_model}/nFeature_RNA_dist.png\n${output_dir}/${train_model}/nFeature_RNA_cutoff${cutoff}.png # for each cut off, including 50, 100, 200, 300, 400, 500, 750, and 1000\n</code></pre></p> <p>Commands: <pre><code>$neda_dir/steps/step2b.1-Seurat-test-cutoff.sh $input_configfile\n</code></pre></p>"},{"location":"analysis/hex_idx/step2b-seurat/#step-2b2-manually-selecting-the-optimal-nfeature_rna-cutoff","title":"Step 2b.2 Manually Selecting the Optimal nFeature_RNA Cutoff","text":"<p>Examine the density plots generated by step 2b.1 to choose a nFeature_RNA cutoff, aiming to remove noise signals. For our example data, we applied a cut off of 500 for deep liver section dataset, and 100 for shallow liver section dataset as well as the minimal test dataset. It is optional to define x y ranges(<code>X_min</code>, <code>X_max</code>, <code>Y_min</code>, and <code>Y_max</code>). </p> <p>Add the following variables to the input configuration file. </p> <p>Example: <pre><code>nFeature_RNA_cutoff=100         ## The cutoff for nFeature_RNA    \nX_min=2.5e+06\nX_max=1e+07\nY_min=1e+06\nY_max=6e+06\n</code></pre></p>"},{"location":"analysis/hex_idx/step2b-seurat/#step-2b3-seurat-clustering-analysis","title":"Step 2b.3 Seurat Clustering Analysis","text":"<p>The step script starts with the removal of mitochondrial and hypothetical genes and the filtering of hexagons based on <code>nFeature_RNA_cutoff</code> and, when applied, X Y ranges. Subsequently, it applies sctransform normalization followed by dimensionality reduction through Principal Component Analysis (PCA) and Uniform Manifold Approximation and Projection (UMAP) embedding.</p> <p>Next, the step script employs <code>FindClusters</code> segregate hexagons into clusters utilizing a shared nearest neighbor (SNN) modularity optimization-based clustering algorithm. The argument <code>resolution</code> in <code>FindClusters</code> determines the \"granularity\" of clusters, i.e., a higher resolution value yields more clusters. Thus, this step will examine the performance of a range of <code>resolutions</code>, including 0.25, 0.5, 0.75, 1, 1.25, 1.5, and 1.75. For each specified resolution, the script generates an UMAP for dimensionality reduction, a spatial plot to visualize the clusters and their spatial arrangement, and a Differential Expression (DE) file, detailing marker genes identified for each cluster.</p> <p>Additionally, this step generates a metadata file containing information on the cluster assignment for each hexagon, and an RDS (R Data Serialization) file that stores the complete Seurat object with all the compiled data.</p> <p>Input &amp; Output <pre><code># Input: \n${output_dir}/${train_model}/features.tsv.gz\n${output_dir}/${train_model}/barcodes.tsv.gz\n${output_dir}/${train_model}/matrix.mtx.gz\n\n# Output: \n${output_dir}/${train_model}/${prefix}_cutoff${nFeature_RNA_cutoff}_metadata.csv                # a metadata file\n${output_dir}/${train_model}/${prefix}_cutoff${nFeature_RNA_cutoff}_SCT.RDS                     # an RDS file\n${output_dir}/${train_model}/${prefix}_cutoff${nFeature_RNA_cutoff}_res${res}_DE.csv            # for each resolution (`$res`) including 0.25, 0.5, 0.75, 1, 1.25, 1.5, and 1.75\n${output_dir}/${train_model}/${prefix}_cutoff${nFeature_RNA_cutoff}_res${res}_DimSpatial.png    # for each resolution (`$res`) including 0.25, 0.5, 0.75, 1, 1.25, 1.5, and 1.75\n</code></pre></p> <p>Commands: <pre><code>$neda_dir/steps/step2b.3-Seurat-clustering.sh $input_configfile\n</code></pre></p>"},{"location":"analysis/hex_idx/step2b-seurat/#step-2b4-manually-selecting-the-optimal-clustering-resolution","title":"Step 2b.4 Manually Selecting the Optimal Clustering Resolution","text":"<p>Examine the UMAP and spatial plots from the step 2b.3 and choose the optimal resolution. Then, save this chosen resolution into the input configuration file as the <code>res_of_interest</code> variable. </p> <p>Example: <pre><code>res_of_interest=1\n</code></pre></p>"},{"location":"analysis/hex_idx/step2b-seurat/#step-2b5-preparing-a-count-matrix","title":"Step 2b.5 Preparing a Count Matrix","text":"<p>Transform the metadata into a count matrix to serve as the model matrix for the subsequent step. Additionally, the number of clusters from the model matrix will be obtained and assigned to the <code>nf</code> variable in the input configuration file.</p> <p>Input &amp; Output <pre><code># Input:\n${output_dir}/${train_model}/features.tsv.gz\n${output_dir}/${train_model}/barcodes.tsv.gz\n${output_dir}/${train_model}/matrix.mtx.gz\n${output_dir}/${train_model}/${prefix}_cutoff${nFeature_RNA_cutoff}_metadata.csv\n\n# Output: \n${output_dir}/${train_model}/${train_prefix}.model_matrix.tsv.gz\n</code></pre></p> <p>Commands: <pre><code>$neda_dir/steps/step2b.5-Seurat-count-matrix.sh $input_configfile\n</code></pre></p>"},{"location":"analysis/hex_idx/step3-transform/","title":"Step 3 Transform","text":"<p>Prefix:</p> <p>The <code>tranform_prefix</code> will be automatically defined by the script as below. <pre><code>tranform_prefix=\"${train_prefix}.prj_${pw}.r_${ar}\"\n</code></pre> * See variables applied above in the Job Configuration.</p>"},{"location":"analysis/hex_idx/step3-transform/#step-31-transform","title":"Step 3.1 Transform","text":"<p>Convert to a factor space using the provided model, which includes gene names and potentially Dirichlet parameters. The pixel-level data will be organized into (potentially overlapping) hexagonal groups. </p> <p>Input &amp; Output <pre><code># Input:\n${output_dir}/${prefix}.transcripts_filtered.tsv.gz\n${output_dir}/${train_model}/${train_prefix}.model_matrix.tsv.gz              \n\n# Output:\n${output_dir}/${train_model}/${tranform_prefix}.fit_result.tsv.gz\n${output_dir}/${train_model}/${tranform_prefix}.posterior.count.tsv.gz\n</code></pre></p> <p>Commands: <pre><code>$neda_dir/steps/step3.1-transform.sh $input_configfile\n</code></pre></p>"},{"location":"analysis/hex_idx/step3-transform/#step-32-transform-visualization","title":"Step 3.2 Transform Visualization","text":"<p>For LDA, simply create a symbolic link from the color table created at step 2a.3 and use it to visualize the transformed data.</p> <p>For Seurat, this step creates a color table and visualize the transformed data. </p> <p>Input &amp; Output <pre><code># Input:\n${output_dir}/${train_model}/${train_prefix}.color.tsv                  # Only if the train model is defined as \"LDA\"\n${output_dir}/${train_model}/${tranform_prefix}.fit_result.tsv.gz\n${output_dir}/${prefix}.coordinate_minmax.tsv\n\n# Output:\n${output_dir}/${train_model}/${tranform_prefix}.rgb.tsv\n${output_dir}/${train_model}/${tranform_prefix}.top.png\n${output_dir}/${train_model}/${tranform_prefix}.png\n</code></pre></p> <p>Commands: <pre><code>$neda_dir/steps/step3.2-transform-visualization.sh $input_configfile\n</code></pre></p>"},{"location":"analysis/hex_idx/step4-decode/","title":"Step 4 Pixel-level Decoding","text":"<p>Prefix:</p> <p>The decode_prefix will be automatically defined as below. <pre><code>decode_prefix=\"${train_prefix}.decode.prj_${pw}.r_${ar}_${nr}\"\n</code></pre></p> <ul> <li><code>nr</code>: represents neighbor_radius. By default, <code>nr=ar+1</code>.</li> <li>Other variables applied above are in the Job Configuration.</li> </ul>"},{"location":"analysis/hex_idx/step4-decode/#step-41-pixel-level-decoding","title":"Step 4.1 pixel-level Decoding.","text":"<p>Decoding the model matrix on individual pixels, which returns a tab-delimited file of the posterior count of factors on individual pixels.</p> <p>Input &amp; Output <pre><code># Input:\n${output_dir}/${prefix}.coordinate_minmax.tsv\n${output_dir}/${prefix}.batched.matrix.tsv.gz\n${output_dir}/${prefix}.transcripts_filtered.tsv.gz\n${output_dir}/${train_model}/${train_prefix}.model_matrix.tsv.gz        \n${output_dir}/${train_model}/${tranform_prefix}.fit_result.tsv.gz\n\n# Output: \n${output_dir}/${train_model}/${decode_prefix}.pixel.sorted.tsv.gz\n</code></pre></p> <p>Commands: <pre><code>$neda_dir/steps/step4.1-pixel-level-decode.sh $input_configfile\n</code></pre></p>"},{"location":"analysis/hex_idx/step4-decode/#step-42-visualizing-pixel-level-decoding-and-generating-marker-gene-reports","title":"Step 4.2 Visualizing Pixel-Level Decoding and Generating Marker Gene Reports","text":"<p>Identifying marker genes for each cluster, and generating a report html file that summarizes individual factors and marker genes. In addition, this step creates a high-resolution image of cell type factors for individual pixels using the color table generated at step 3.2.</p> <p>Input &amp; Output <pre><code># Input:\n${output_dir}/${train_model}/${decode_prefix}.posterior.count.tsv.gz\n${output_dir}/${train_model}/${tranform_prefix}.rgb.tsv\n\n# Output: \n${output_dir}/${train_model}/${decode_prefix}.bulk_chisq.tsv\n${output_dir}/${train_model}/${decode_prefix}.factor.info.html\n${output_dir}/${train_model}/${decode_prefix}.pixel.png\n</code></pre></p> <p>Commands: <pre><code>$neda_dir/steps/step4.2-pixel-level-visualization-and-report.sh $input_configfile\n</code></pre></p>"},{"location":"home/documentation_overview/","title":"Documentation Overview","text":"<p>The current documentation include the following sections:</p> <p>Home:</p> <ul> <li>Documentation Overview: Provides a summary of the contents and structure of NEDA.</li> </ul> <p>Installation:</p> <ul> <li>Installing NEDA: Guidelines on installing NEDA and its dependent software tools.</li> <li>Example Datasets: Information on accessing three provided example datasets.</li> </ul> <p>Pixel-level Analysis:</p> <ul> <li>Introduction: Introduction to Pixel-level Analysis in NEDA.</li> <li>Preparing Input Data: Overview of required input files.</li> <li>Preparing Job Configuration: Preparing the input configuration file.</li> <li>Preprocessing: Initialize computing environment and data preprocessing.</li> <li>LDA Factorization: Application of Latent Dirichlet Allocation (LDA) for spatial factor identification.</li> <li>Seurat Clustering: Multi-dimensional clustering with <code>Seurat</code> to identify cell types.</li> <li>Transform: Converting to a factor space using the provided model via <code>FICTURE</code>.</li> <li>Pixel-level Decoding: Decoding of pixel-level factors or clusters using <code>FICTURE</code>.</li> </ul> <p>Cell Segmentation-based Analysis:</p> <ul> <li>Introduction: An Overview of the prelimary single-cell analysis.</li> <li>Preparing Input: Details of required input files.</li> <li>Create Cell-indexed SGE: Computing environment setup and preparation of a cell-indexed spatial digital gene expression matrix </li> <li>Seurat Clustering: Application of multi-dimensional clustering with <code>Seurat</code> for cell type factor inference.</li> </ul>"},{"location":"installation/example_data/","title":"Accessing Example Datasets","text":"<p>We have made available three datasets associated with the NovaScope protocol to be used as input for the NovaScope Exemplary Downstream Analysis (NEDA). </p>"},{"location":"installation/example_data/#data-overview","title":"Data Overview","text":"<p>Created using NovaScope, these datasets originate from FASTQ files derived from the same liver tissue section of an 8-week-old C57BL/6 wild-type male mouse. </p>"},{"location":"installation/example_data/#minimal-test-run-dataset","title":"Minimal Test Run Dataset","text":"<p>The minimal test run dataset was created using a subset of a liver section with a relatively shallow depth in the 2nd sequencing. This dataset is intended for preliminary testing of NEDA, primarily for validating NEDA scripts' functionality. It is not designed to yield biological insights.</p>"},{"location":"installation/example_data/#shallow-liver-section-dataset","title":"Shallow Liver Section Dataset","text":"<p>This dataset was generated by a Seq-Scope dataset for a tissue section, characterized by a relatively shallow 2nd-Seq library sequencing depth (i.e., approximately 163 million paired-end reads). The dataset from FASTQ files with such depth should be sufficient to investigate major cell types alongside marker genes pertaining to liver cell diversity and perform basic pixel-level decoding of the spatial transcriptome. This dataset comes along with a set of aligned Hematoxylin and Eosin (H&amp;E) stained histology images. </p>"},{"location":"installation/example_data/#deep-liver-section-dataset","title":"Deep Liver Section Dataset","text":"<p>The initial examination of the shallow dataset was encouraging, prompting a more extensive sequencing of the sample tissue to fully saturate the library (i.e., approximately 2.61 billion paired-end reads). The deep dataset was produced using all pairs of 2nd-seq FASTQ files. While datasets with shallower sequencing depths offer valuable insights, deep sequencing allows for a more thorough exploration of the data. This dataset also includes a set of aligned H&amp;E stained histology images. </p>"},{"location":"installation/example_data/#download-datasets","title":"Download Datasets","text":"<p>All datasets are provided under a single DOI, accessible via this URL: https://doi.org/10.5281/zenodo.10841777. The most recent version of the dataset is version 3.</p> <p>Since Pixel-level Analysis and Cell Segmentation-based Analysis require different input files, we have provided these files in separate tarball archives. Only the shallow liver dataset and deep liver dataset include input files for the Cell Segmentation-based Analysis due to the availability of histology files.</p>"},{"location":"installation/example_data/#input-for-spatial-transcriptomic-analysis","title":"Input for Spatial Transcriptomic analysis","text":"<p>The tarball files with this naming convention is input files for Pixel-level Analysis: </p> <pre><code>&lt;prefix&gt;_pixel_&lt;release_date&gt;.tar.gz\n</code></pre> <ul> <li>Minimal Test Run Dataset : </li> </ul> <pre><code>## To download the tarball from Zenodo, you can use the following command.\ncurl -o minimal_pixel_20240519.tar.gz https://zenodo.org/records/11218168/files/minimal_pixel_20240519.tar.gz?download=1\n\n## (Optional) Verify the integrity of the tarball file.\ncurl -o minimal_pixel_20240519.tar.gz.md5 https://zenodo.org/records/11218168/files/minimal_pixel_20240519.tar.gz.md5?download=1\nmd5sum -c minimal_pixel_20240519.tar.gz.md5\n\n## Uncompress the tarball using the following command.\ntar -zxvf minimal_pixel_20240519.tar.gz\n</code></pre> <ul> <li>Shallow Liver Section Dataset:</li> </ul> <pre><code>## To download the tarball from Zenodo, you can use the following command.\ncurl -o  shallow_pixel_20240519.tars.gz https://zenodo.org/records/11218168/files/shallow_pixel_20240519.tar.gz?download=1\n\n## (Optional) Verify the integrity of the tarball file.\ncurl -o  shallow_pixel_20240519.tar.gz.md5 https://zenodo.org/records/11218168/files/shallow_pixel_20240519.tar.gz.md5?download=1\nmd5sum -c  shallow_pixel_20240519.tar.gz.md5\n\n## Uncompress the tarball using the following command.\ntar -zxvf  shallow_pixel_20240519.tar.gz\n</code></pre> <ul> <li>Deep Liver Section Dataset:</li> </ul> <pre><code>## To download the tarball from Zenodo, you can use the following command.\ncurl -o deep_pixel_20240519.tar.gz https://zenodo.org/records/11218168/files/deep_pixel_20240519.tar.gz?download=1\n\n## (Optional) Verify the integrity of the tarball file.\ncurl -o deep_pixel_20240519.tar.gz.md5 https://zenodo.org/records/11218168/files/deep_pixel_20240519.tar.gz.md5?download=1\nmd5sum -c deep_pixel_20240519.tar.gz.md5\n\n## Uncompress the tarball using the following command.\ntar -zxvf deep_pixel_20240519.tar.gz\n</code></pre>"},{"location":"installation/example_data/#input-for-cell-segmentation-based-analysis","title":"Input for Cell Segmentation-based Analysis","text":"<p>The tarball files with this naming convention is input files for Cell Segmentation-based Analysis: </p> <pre><code>&lt;prefix&gt;_cellseg_&lt;release_date&gt;.tar.gz\n</code></pre> <ul> <li>Shallow Liver Section Dataset:</li> </ul> <pre><code>## To download the tarball from Zenodo, you can use the following command.\ncurl -o  shallow_cellseg_20240519.tars.gz https://zenodo.org/records/11218168/files/shallow_cellseg_20240519.tar.gz?download=1\n\n## (Optional) Verify the integrity of the tarball file.\ncurl -o  shallow_cellseg_20240519.tar.gz.md5 https://zenodo.org/records/11218168/files/shallow_cellseg_20240519.tar.gz.md5?download=1\nmd5sum -c  shallow_cellseg_20240519.tar.gz.md5\n\n## Uncompress the tarball using the following command.\ntar -zxvf  shallow_cellseg_20240519.tar.gz\n</code></pre> <ul> <li>Deep Liver Section Dataset:</li> </ul> <pre><code>## To download the tarball from Zenodo, you can use the following command.\ncurl -o deep_cellseg_20240519.tar.gz https://zenodo.org/records/11218168/files/deep_cellseg_20240519.tar.gz?download=1\n\n## (Optional) Verify the integrity of the tarball file.\ncurl -o deep_cellseg_20240519.tar.gz.md5 https://zenodo.org/records/11218168/files/deep_cellseg_20240519.tar.gz.md5?download=1\nmd5sum -c deep_cellseg_20240519.tar.gz.md5\n\n## Uncompress the tarball using the following command.\ntar -zxvf deep_cellseg_20240519.tar.gz\n</code></pre>"},{"location":"installation/installation/","title":"Installing NEDA","text":""},{"location":"installation/installation/#1-install-the-novascope-exemplary-downstream-analysis-neda","title":"1. Install the NovaScope-exemplary-downstream-analysis (NEDA)","text":"<p>Use <code>--recursive</code> to make sure both NEDA and its submodule are cloned. </p> <pre><code>git clone --recursive git@github.com:seqscope/NovaScope-exemplary-downstream-analysis.git \n</code></pre>"},{"location":"installation/installation/#2-install-software-and-dependencies","title":"2. Install Software and Dependencies","text":""},{"location":"installation/installation/#21-install-dependent-softwares","title":"2.1 Install Dependent Softwares","text":"<p>Ensure the installation of the below software to facilitate analysis. The versions listed below have been confirmed for compatibility with NEDA while alternative versions may also work with it.</p> <p>High-performance computing (HPC) users can easily load these programs using the <code>module load</code> command. It's advisable to first check availability with <code>module available</code> or <code>module spider</code>.</p> <ul> <li>Samtools (v1.14)</li> <li>Python (v3.10) </li> <li>R (v4.2)</li> </ul>"},{"location":"installation/installation/#22-install-ficture-and-its-dependencies","title":"2.2 Install FICTURE and Its Dependencies","text":"<p>Info</p> <p>Please view FICTURE's official documentation for the latest instruction.</p>"},{"location":"installation/installation/#221-install-ficture","title":"2.2.1 Install FICTURE","text":"<p>NEDA has included FICTURE as a submodule. We suggest the users to double check the <code>submodule/ficture</code> folder to make sure the FICTURE has been cloned successfully:</p> <pre><code>## define the path of NEDA \nneda_dir=/path/to/neda\n\n## double-check the ficture directory\nls -hlt $neda_dir/submodules/ficture\n</code></pre>"},{"location":"installation/installation/#222-create-a-python-environment","title":"2.2.2 Create a Python Environment","text":"<p>Set up a Python environment for FICTURE as per the requirement file. The requirement file is included in the FICTURE repository.</p> <p>First, ensure the requirements file is accessible:</p> <pre><code>## path to the requirement file in the FICTURE repository\nficture_reqfile=$neda_dir/submodules/ficture/requirements.txt\n\n## verify the existence of the requirement file.\nif [ -f \"$ficture_reqfile\" ]; then\n    echo -e \"The requirement file for FICTURE exists.\"\nelse\n    echo -e \"Error: The requirement file for FICTURE does not exist.\\n\"\n    echo -e \"Now downloading such requirement file...\"\n    curl -o $ficture_reqfile https://raw.githubusercontent.com/seqscope/ficture/8ceb419618c1181bb673255427b53198c4887cfa/requirements.txt\nfi\n</code></pre> <p>Now, install the required packages. Below is an example of creating a new Python environment using <code>venv</code>. It's also possible to establish such environments through alternative methods, including <code>conda</code>, <code>virtualenv</code>, and <code>pyenv</code>.</p> <pre><code>## set the path to the Python virtual environment directory\npyenv_dir=/path/to/python/virtual/environment/directory\npyenv_name=name_of_python_venv\n\n## create the Python virtual environment (need to be done only once)\nmkdir -p ${pyenv_dir}\ncd ${pyenv_dir}\npython -m venv ${pyenv_name}\n\n## activate the Python environment (every time you want to use the environment)\nsource ${pyenv_name}/bin/activate\n\n## install the required packages (need to be done only once)\npip install -r $$ficture_reqfile\n</code></pre>"},{"location":"installation/installation/#23-install-r-packages","title":"2.3 Install R Packages","text":"<p>To enable Seurat analysis, install the following required R packages:</p> <ul> <li>Seurat</li> <li>ggplot2</li> <li>patchwork</li> <li>dplyr</li> <li>tidyverse</li> <li>stringr</li> <li>cowplot</li> <li>optparse</li> <li>RColorBrewer</li> </ul> <pre><code>## install all required packages in R\ninstall.packages(c( \"Seurat\", \"optparse\", \"patchwork\", \"dplyr\", \"tidyverse\", \"stringr\", \n                    \"ggplot2\", \"cowplot\", \"RColorBrewer\"))\n</code></pre>"}]}