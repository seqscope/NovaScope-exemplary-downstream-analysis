{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to NovaScope Exemplary Downstream Analysis (NEDA) documentation","text":""},{"location":"#introduction","title":"Introduction","text":"<p>This is an exemplary downstream analysis for spatial transcriptomics data from NovaScope. </p> <p>Currently, the NovaScope Exemplary Downstream Analysis (NEDA) is designed to provide two strategies to analyze the spatial digital gene expression (SGE) matrix, including:</p> <p>1) Latent Dirichlet Allocation (LDA) + FICTURE:     This strategy utilizes Latent Dirichlet Allocation (LDA) to identify spatial factors. Subsequently, FICTURE is employed to map these identified factors onto a histological space with pixel-level resolution.</p> <p>2) Seurat + FICTURE:      In this strategy, multi-dimensional clustering via Seurat is applied to explore cell type clusters. These clusters are then projected into a histological space, achieving pixel-level resolution through the use of FICTURE.</p>"},{"location":"#a-brief-overview","title":"A Brief Overview","text":"<p> Figure 1: A Brief overview of the inputs, outputs, and process steps in NovaScope Exemplary Downstream Analysis (NEDA). The strategies \"Latent Dirichlet allocation (LDA) + FICTURE\" and \"Seurat + FICTURE\" share the scripts of step1.preprocessing step3.transform, and step4.pixel-level decoding. Their differences lie in two main areas: the configuration file used for input; and the procedures and output files in the second step. Details for each step are provided in the Starting Downstream Analysis. SGE: spatial digital gene expression. </p>"},{"location":"analysis/intro/","title":"Introduction","text":"<p>This tutorial provides an step-by-step instruction of running NovaScope-exemplary-downstream-analysis (NEDA) for each analytical strategy.</p> <p>Before kicking off the analysis, please first install NEDA in your computing environment, download the example inputs datasets, and prepare the input configuration file.</p> <p>Next, start with this to set up your computing environment and preprocess the input spatial digital gene expression (SGE) matrix, ensuring it's ready for analysis.</p> <p>Finally, select the analytical strategy that best suits your needs or interests from Latent Dirichlet Allocation (LDA) + FICTURE, and Seurat + FICTURE. For implementing LDA analysis, refer to this instruction. If you wish to conduct Seurat analysis, begin with this step. Each step's instructions cover:</p> <ul> <li>The purpose of the step;</li> <li>The execution command;</li> <li>The necessary input and output files, enhancing clarity;</li> <li>Definitions of auxiliary parameters are outlined in the script for each step, as applicable.</li> </ul>"},{"location":"analysis/step1-preprocess/","title":"Initialize Computing Environment and Data Preprocessing","text":""},{"location":"analysis/step1-preprocess/#set-up-computing-environment","title":"Set Up Computing Environment","text":"<p>Please make sure set up the computing environment before each step. </p> <pre><code>## Load modules, if applicable.\n## For non-HPC user, use `export` to set the paths for following softwares, e.g., `export samtools=&lt;path_to_samtools&gt;`.\nmodule load Bioinformatics                          ## In this example, samtools is part of the Bioinformatics module system, requiring the Bioinformatics module to be loaded before accessing the specific program.\nmodule load samtools\n\nmodule load R/4.2.0e                                ## R is only required for Seurat+FICTURE analysis.\n\n## If your Python environment was not set up using venv, replace the following lines with the appropriate commands to activate the environment.\npy_env=\"&lt;path_to_python_env&gt;\"                       ## replace &lt;path_to_python_env&gt; with the path to the python environment\nsource ${py_env}/bin/activate\nexport python=${py_env}/bin/python\n\nneda_dir=\"&lt;path_to_the_NEDA_repository&gt;\"            ## replace &lt;path_to_the_NEDA_repository&gt; with the path to the NovaScope-exemplary-downstream-analysis repository\n\ninput_configfile=\"&lt;path_to_input_data_and_params&gt;\"  ## replace &lt;path_to_input_data_and_params&gt; with the path to the input_data_and_params file, e.g., ${neda_dir}/input_data_and_params/input_data_and_params_lda.txt\n</code></pre>"},{"location":"analysis/step1-preprocess/#step-1-preprocessing","title":"Step 1. Preprocessing","text":""},{"location":"analysis/step1-preprocess/#step-11-convert-spatial-digital-gene-expression-sge-matrix-into-a-ficture-compatible-format","title":"Step 1.1 Convert Spatial Digital Gene Expression (SGE) Matrix into a FICTURE-compatible Format","text":"<p>This step converts the spatial digital gene expression (SGE) matrix to FICTURE format, where each row contains, X/Y coordinates, gene name, identifier, and observed count.</p> <p>Input &amp; Output <pre><code># Input:\n${input_dir}/features.tsv.gz\n${input_dir}/barcodes.tsv.gz\n${input_dir}/matrix.mtx.gz\n\n#Output:\n${output_dir}/${prefix}.merged.matrix.tsv.gz\n</code></pre></p> <p>Command: <pre><code>$neda_dir/steps/step1.1-convert-SGE.sh $input_configfile\n</code></pre></p>"},{"location":"analysis/step1-preprocess/#step-12-filtering","title":"Step 1.2 Filtering","text":"<p>Prepare a quality-controlled (QCed) feature file and SGE matrix into a FICTURE-compatible format, filtered by gene types and density. This also creates a strict boundary file based on the density of transcripts.</p> <p>Input &amp; Output <pre><code># Input: \n${input_dir}/features.tsv.gz\n${input_dir}/barcodes.tsv.gz\n${input_dir}/matrix.mtx.gz\n${output_dir}/${prefix}.merged.matrix.tsv.gz\n\n#Output: \n${output_dir}/${prefix}.feature.clean.tsv.gz\n${output_dir}/${prefix}.QCed.matrix.tsv.gz\n${output_dir}/${prefix}.boundary.strict.geojson\n${output_dir}/${prefix}.coordinate_minmax.tsv\n</code></pre></p> <p>Command: <pre><code>$neda_dir/steps/step1.2-filter-feature-and-SGE.sh $input_configfile\n</code></pre></p>"},{"location":"analysis/step1-preprocess/#step-13-create-minimatch","title":"Step 1.3 Create Minimatch","text":"<p>Reformat the input file by assigning minibatch label, and by reordering the data based on the major axis so that they are locally contiguous.</p> <p>Input &amp; Output <pre><code>#Input: \n${output_dir}/${prefix}.QCed.matrix.tsv.gz\n\n#Output: \n${output_dir}/${prefix}.batched.matrix.tsv.gz\n</code></pre></p> <p>Command: <pre><code>$neda_dir/steps/step1.3-create-minibatch.sh $input_configfile\n</code></pre></p>"},{"location":"analysis/LDA/step2a-LDA/","title":"Latent Dirichlet Allocation (LDA) + FICTURE analytical strategy","text":""},{"location":"analysis/LDA/step2a-LDA/#step-2a-infer-cell-type-factors-using-latent-dirichlet-allocation-lda","title":"Step 2a. Infer Cell Type Factors using Latent Dirichlet Allocation (LDA).","text":"<p>This example illustrates infering cell type factors using Latent Dirichlet Allocation (LDA). </p> <p>Prefix:</p> <p>To clarify the input and output filenames, we utilize prefixes in this documentation. Below, we illustrate how these prefixes are defined. Those prefixes are automatically defined by the script; users do NOT need to manually define them. </p> <pre><code>hexagon_prefix=\"${prefix}.hexagon.${sf}.d_${tw}\"\ntrain_prefix=\"${prefix}.${sf}.nF${nf}.d_${tw}.s_${ep}\"\n</code></pre> <ul> <li>Details on variables used in above prefixes are in the Job Configuration.</li> </ul>"},{"location":"analysis/LDA/step2a-LDA/#step-2a1-create-hexagonal-spatial-gene-expression-sge-matrix","title":"Step 2a.1 Create Hexagonal Spatial Gene Expression (SGE) matrix","text":"<p>Given a specified size of hexagons, segment the raw spatial gene expression (SGE) matrix into hexagonal SGE.</p> <p>Input &amp; Output <pre><code># Input:\n${output_dir}/${prefix}.QCed.matrix.tsv.gz\n${output_dir}/${prefix}.boundary.strict.geojson\n\n# Output: \n${output_dir}/${train_model}/${hexagon_prefix}.tsv.gz\n</code></pre></p> <p>Command: <pre><code>$neda_dir/steps/step2a.1-create-hexagons.sh $input_configfile\n</code></pre></p>"},{"location":"analysis/LDA/step2a-LDA/#step-2a2-lda-factorization","title":"Step 2a.2 LDA Factorization","text":"<p>An unsupervised learning of cell type factors using LDA.</p> <p>Input &amp; Output: <pre><code># Input:\n${output_dir}/${prefix}.feature.clean.tsv.gz\n${output_dir}/${train_model}/${hexagon_prefix}.tsv.gz\n\n# Output: \n${output_dir}/${train_model}/${train_prefix}.model.p\n${output_dir}/${train_model}/${train_prefix}.fit_result.tsv.gz\n${output_dir}/${train_model}/${train_prefix}.posterior.count.tsv.gz\n</code></pre></p> <p>Command: <pre><code>$neda_dir/steps/step2a.2-LDA-factorization.sh $input_configfile\n</code></pre></p>"},{"location":"analysis/LDA/step2a-LDA/#step-2a3-creating-marker-gene-reports","title":"Step 2a.3 Creating Marker Gene Reports","text":"<p>This step includes: generating a color table, identifying marker genes for each factor, and creating a report html file, which summarizes individual factors and marker genes.</p> <p>Input &amp; Output: <pre><code># Input:\n${output_dir}/${train_model}/${train_prefix}.fit_result.tsv.gz\n${output_dir}/${train_model}/${train_prefix}.posterior.count.tsv.gz\n\n# Output: \n${output_dir}/${train_model}/${train_prefix}.color.tsv\n${output_dir}/${train_model}/${train_prefix}.bulk_chisq.tsv\n${output_dir}/${train_model}/${train_prefix}.factor.info.html\n</code></pre></p> <p>Command: <pre><code>$neda_dir/steps/step2a.3-LDA-factorization-report.sh $input_configfile\n</code></pre></p>"},{"location":"analysis/LDA/step3-transform/","title":"Latent Dirichlet Allocation (LDA) + FICTURE analytical strategy","text":""},{"location":"analysis/LDA/step3-transform/#step-3-transform","title":"Step 3 Transform","text":"<p>Prefix:</p> <p>The <code>tranform_prefix</code> will be automatically defined by the script as below. <pre><code>tranform_prefix=\"${train_prefix}.prj_${pw}.r_${ar}\"\n</code></pre> * See variables applied above in the Job Configuration.</p>"},{"location":"analysis/LDA/step3-transform/#step-31-transform","title":"Step 3.1 Transform","text":"<p>Convert to a factor space using the provided model, which includes gene names and potentially Dirichlet parameters. The pixel-level data will be organized into (potentially overlapping) hexagonal groups.</p> <p>Input &amp; Output <pre><code>#Input:\n${output_dir}/${prefix}.QCed.matrix.tsv.gz\n${output_dir}/${train_model}/${train_prefix}.model.p                    # The format of the model file varies between LDA and Seurat.\n\n#Output:\n${output_dir}/${train_model}/${tranform_prefix}.fit_result.tsv.gz\n${output_dir}/${train_model}/${tranform_prefix}.posterior.count.tsv.gz\n</code></pre></p> <p>Command: <pre><code>$neda_dir/steps/step3.1-transform.sh $input_configfile\n</code></pre></p>"},{"location":"analysis/LDA/step3-transform/#step-32-transform-visualization","title":"Step 3.2 Transform Visualization","text":"<p>For LDA, simply use the color table created at step 2a.3 to visualize the transformed data.</p> <p>Input &amp; Output <pre><code># Input:\n${output_dir}/${train_model}/${tranform_prefix}.fit_result.tsv.gz\n${output_dir}/${train_model}/${tranform_prefix}.posterior.count.tsv.gz\n${output_dir}/${prefix}.coordinate_minmax.tsv\n\n#Output:\n${output_dir}/${train_model}/${tranform_prefix}.rgb.tsv\n${output_dir}/${train_model}/${tranform_prefix}.top.png\n</code></pre></p> <p>Command: <pre><code>$neda_dir/steps/step3.2-transform-visualization.sh $input_configfile\n</code></pre></p>"},{"location":"analysis/LDA/step4-decode/","title":"Latent Dirichlet Allocation (LDA) + FICTURE analytical strategy","text":""},{"location":"analysis/LDA/step4-decode/#step-4-pixel-level-decoding","title":"Step 4 Pixel-level Decoding","text":"<p>Prefix:</p> <p>The decode_prefix will be automatically defined as below. <pre><code>decode_prefix=\"${train_prefix}.decode.prj_${pw}.r_${ar}_${nr}\"\n</code></pre> * <code>nr</code>: represents neighbor_radius. By default, <code>nr=ar+1</code>. * Other variables applied above are in the Job Configuration.</p>"},{"location":"analysis/LDA/step4-decode/#step-41-pixel-level-decoding","title":"Step 4.1 Pixel-level Decoding.","text":"<p>Decoding the model matrix on individual pixels, which returns a tab-delimited file of the posterior count of factors on individual pixels.</p> <p>Input &amp; Output <pre><code># Input:\n${output_dir}/${prefix}.coordinate_minmax.tsv\n${output_dir}/${prefix}.batched.matrix.tsv.gz\n${output_dir}/${prefix}.QCed.matrix.tsv.gz\n${output_dir}/${train_model}/${tranform_prefix}.model.p         # The format of the model file varies between LDA and Seurat.\n${output_dir}/${train_model}/${tranform_prefix}.fit_result.tsv.gz\n\n#Output: \n${output_dir}/${train_model}/${decode_prefix}.pixel.sorted.tsv.gz\n</code></pre></p> <p>Command: <pre><code>$neda_dir/steps/step4.1-pixel-level-decode.sh $input_configfile\n</code></pre></p>"},{"location":"analysis/LDA/step4-decode/#step-42-visualizing-pixel-level-decoding-and-generating-marker-gene-reports","title":"Step 4.2 Visualizing Pixel-Level Decoding and Generating Marker Gene Reports","text":"<p>Identifying marker genes for each factor/cluster, and generating a report html file that summarizes individual factors and marker genes. In addition, this step creates a high-resolution image of cell type factors for individual pixels, using the color table created in step 2a.3.</p> <p>Input &amp; Output <pre><code>#Input:\n${output_dir}/${train_model}/${decode_prefix}.posterior.count.tsv.gz\n${output_dir}/${train_model}/${tranform_prefix}.rgb.tsv\n\n#Output: \n${output_dir}/${train_model}/${decode_prefix}.bulk_chisq.tsv\n${output_dir}/${train_model}/${decode_prefix}.factor.info.html\n${output_dir}/${train_model}/${decode_prefix}.pixel.png\n</code></pre></p> <p>Command: <pre><code>$neda_dir/steps/step4.2-pixel-level-visualization-and-report.sh $input_configfile\n</code></pre></p>"},{"location":"analysis/Seurat/step2b-seurat/","title":"Seurat + FICTURE analytical strategy","text":""},{"location":"analysis/Seurat/step2b-seurat/#step-2b-infer-cell-type-factors-using-seurat","title":"Step 2b. Infer Cell Type Factors using Seurat","text":"<p>This example illustrates infering cell type factors using Seurat. This process contains two stops that require manual evaluation, including one at step 2b.2 and the other at step 2b.4. </p> <p>Prefix:</p> <p>This documentation uses the following prefixes to illustrate input and output filenames, which are automatically assigned by the script. </p> <pre><code>hexagon_prefix=\"${prefix}.hexagon.${sf}.d_${tw}\"\ntrain_prefix=\"${prefix}.${sf}.nF${nf}.d_${tw}.s_${ep}\"    \n</code></pre> <ul> <li>The <code>nf</code> will be determined in step 2b.5.</li> <li>Details on variables used in above prefixes are in the Job Configuration.</li> </ul>"},{"location":"analysis/Seurat/step2b-seurat/#step-2b1-create-hexagonal-spatial-digital-gene-expression-sge-matrix-and-test-nfeature_rna-cutoffs","title":"Step 2b.1 Create Hexagonal Spatial Digital Gene Expression (SGE) Matrix and Test nFeature_RNA Cutoffs","text":"<p>This step creates hexagonal spatial gene expression (SGE) matrix that is compatible with Seurat. It analyzes the distribution of Ncount and Nfeature, and tests filtering the SGE using different nFeature_RNA cutoffs, including 50, 100, 200, 300, 400, 500, 750, and 1000. For each nFeature_RNA cutoff, a density plot is produced to effectively illustrate its efficacy.</p> <p>Input &amp; Output <pre><code># Input:\n${output_dir}/${prefix}.merged.matrix.tsv.gz\n${output_dir}/${prefix}.feature.tsv.gz\n\n# Output: \n# * Hexagonal SGE: \n        ${output_dir}/${train_model}/features.tsv.gz\n        ${output_dir}/${train_model}/barcodes.tsv.gz\n        ${output_dir}/${train_model}/matrix.mtx.gz\n# * Evaluation files: \n        ${output_dir}/${train_model}/Ncount_Nfeature_vln.png\n        ${output_dir}/${train_model}/nFeature_RNA_dist.png\n        # * for each cut off ${cutoff} in 50, 100, 200, 300, 400, 500, 750, and 1000:\n                ${output_dir}/${train_model}/nFeature_RNA_cutoff${cutoff}.png\n</code></pre></p> <p>Command: <pre><code>$neda_dir/steps/step2b.1-creat-hexagons-for-Seurat.sh $input_configfile\n</code></pre></p>"},{"location":"analysis/Seurat/step2b-seurat/#step-2b2-select-the-optimal-nfeature_rna-cutoff","title":"Step 2b.2 Select the Optimal nFeature_RNA Cutoff","text":"<p>Examine the density plots generated by step 2b.1 to choose a cutoff for nFeature_RNA, aiming to remove noise signals. For our example data, we applied a cut off of 500 for deep liver section dataset, and 100 for shallow liver section data. </p> <p>It is optional to define x y ranges. </p> <p>Add those variables to the <code>input_data_and_params</code> file.</p> <p>Example: <pre><code># In this case, the Y_max is not applied. \nnFeature_RNA_cutoff=100\nX_min=2.5e+06\nX_max=1e+07\nY_min=1e+06\n</code></pre></p>"},{"location":"analysis/Seurat/step2b-seurat/#step-2b3-seurat-clustering-analysis","title":"Step 2b.3 Seurat Clustering Analysis","text":"<p>The <code>Seurat_analysis.R</code> script, by default, evaluates clustering at various resolutions, specifically 0.25, 0.5, 0.75, 1, 1.25, 1.5, and 1.75. </p> <p>For each resolution level, it creates a Dimensionality Reduction and Spatial plot to illustrate the clusters through Uniform Manifold Approximation and Projection (UMAP) along with their spatial distribution. It also produces a Differential Expression (DE) file that lists the marker genes for each cluster.</p> <p>Additionally, this step generates a metadata file containing information on the cluster assignment for each hexagon, and an RDS file that stores the complete Seurat object with all the compiled data.</p> <p>Input &amp; Output <pre><code># Input: \n${output_dir}/${train_model}/features.tsv.gz\n${output_dir}/${train_model}/barcodes.tsv.gz\n${output_dir}/${train_model}/matrix.mtx.gz\n\n#Output: \n# * A metadata file:\n        ${output_dir}/${train_model}/${prefix}_cutoff${nFeature_RNA_cutoff}_metadata.csv\n# * An RDS file:\n        ${output_dir}/${train_model}/${prefix}_cutoff${nFeature_RNA_cutoff}_SCT.RDS\n# * For each resolution (`$res`) in 0.25, 0.5, 0.75, 1, 1.25, 1.5, and 1.75:\n        ${output_dir}/${train_model}/${prefix}_cutoff${nFeature_RNA_cutoff}_res${res}_DE.csv\n        ${output_dir}/${train_model}/${prefix}_cutoff${nFeature_RNA_cutoff}_res${res}_DimSpatial.png\n</code></pre></p> <p>Command: <pre><code>$neda_dir/steps/step2b.3-Seurat-clustering.sh $input_configfile\n</code></pre></p>"},{"location":"analysis/Seurat/step2b-seurat/#step-2b4-select-the-optimal-clustering-resolution","title":"Step 2b.4 Select the Optimal Clustering Resolution","text":"<p>Examine the Dimensionality Reduction and Spatial plots from the step 2b.3 and choose a resolution to continue with. Then, save this chosen resolution into the <code>input_data_and_params</code> file as the res_of_interest variable. </p> <p>Example: <pre><code>res_of_interest=1\n</code></pre></p>"},{"location":"analysis/Seurat/step2b-seurat/#step-2b5-prepare-a-count-matrix","title":"Step 2b.5 Prepare a Count Matrix","text":"<p>Transform the metadata into a count matrix to serve as the model matrix for the subsequent step.  Additionally, the number of clusters from the model matrix will be obtained and assigned to the <code>nf</code> variable in the <code>input_data_and_params</code> file.</p> <p>Input &amp; Output <pre><code>#Input:\n${output_dir}/${train_model}/features.tsv.gz\n${output_dir}/${train_model}/barcodes.tsv.gz\n${output_dir}/${train_model}/matrix.mtx.gz\n${output_dir}/${train_model}/${prefix}_cutoff${nFeature_RNA_cutoff}_metadata.csv\n\n#Output: \n${output_dir}/${train_model}/${train_prefix}.model.tsv.gz\n</code></pre></p> <p>Command: <pre><code>$neda_dir/steps/step2b.5-Seurat-count-matrix.sh $input_configfile\n</code></pre></p>"},{"location":"analysis/Seurat/step3-transform/","title":"Seurat + FICTURE analytical strategy","text":""},{"location":"analysis/Seurat/step3-transform/#step-3-transform","title":"Step 3 Transform","text":"<p>Prefix:</p> <p>The <code>tranform_prefix</code> will be automatically defined by the script as below.</p> <pre><code>tranform_prefix=\"${train_prefix}.prj_${pw}.r_${ar}\"\n</code></pre> <ul> <li>See variables applied above in the Job Configuration.</li> </ul>"},{"location":"analysis/Seurat/step3-transform/#step-31-transform","title":"Step 3.1 Transform","text":"<p>Convert to a factor space using the provided model, which includes gene names and potentially Dirichlet parameters. The pixel-level data will be organized into (potentially overlapping) hexagonal groups.</p> <p>Input &amp; Output <pre><code>#Input:\n${output_dir}/${prefix}.QCed.matrix.tsv.gz\n${output_dir}/${train_model}/${train_prefix}.model.tsv.gz               # The format of the model file varies between LDA and Seurat.\n\n#Output:\n${output_dir}/${train_model}/${tranform_prefix}.fit_result.tsv.gz\n${output_dir}/${train_model}/${tranform_prefix}.posterior.count.tsv.gz\n</code></pre></p> <p>Command: <pre><code>$neda_dir/steps/step3.1-transform.sh $input_configfile\n</code></pre></p>"},{"location":"analysis/Seurat/step3-transform/#step-32-transform-visualization","title":"Step 3.2 Transform Visualization","text":"<p>For Seurat, create a color table and visualize the transformed data. </p> <p>Input &amp; Output <pre><code># Input:\n${output_dir}/${train_model}/${tranform_prefix}.fit_result.tsv.gz\n${output_dir}/${train_model}/${tranform_prefix}.posterior.count.tsv.gz\n${output_dir}/${prefix}.coordinate_minmax.tsv\n\n#Output:\n${output_dir}/${train_model}/${tranform_prefix}.rgb.tsv\n${output_dir}/${train_model}/${tranform_prefix}.top.png\n</code></pre></p> <p>Command: <pre><code>$neda_dir/steps/step3.2-transform-visualization.sh $input_configfile\n</code></pre></p>"},{"location":"analysis/Seurat/step4-decode/","title":"Seurat + FICTURE analytical strategy","text":""},{"location":"analysis/Seurat/step4-decode/#step-4-pixel-level-decoding","title":"Step 4 Pixel-level Decoding","text":"<p>Prefix:</p> <p>The decode_prefix will be automatically defined as below. <pre><code>decode_prefix=\"${train_prefix}.decode.prj_${pw}.r_${ar}_${nr}\"\n</code></pre></p> <ul> <li><code>nr</code>: represents neighbor_radius. By default, <code>nr=ar+1</code>.</li> <li>Other variables applied above are in the Job Configuration.</li> </ul>"},{"location":"analysis/Seurat/step4-decode/#step-41-pixel-level-decoding","title":"Step 4.1 pixel-level Decoding.","text":"<p>Decoding the model matrix on individual pixels, which returns a tab-delimited file of the posterior count of factors on individual pixels.</p> <p>Input &amp; Output <pre><code># Input:\n${output_dir}/${prefix}.coordinate_minmax.tsv\n${output_dir}/${prefix}.batched.matrix.tsv.gz\n${output_dir}/${prefix}.QCed.matrix.tsv.gz\n${output_dir}/${train_model}/${tranform_prefix}.model.tsv.gz        # The format of the model file varies between LDA and Seurat.\n${output_dir}/${train_model}/${tranform_prefix}.fit_result.tsv.gz\n\n#Output: \n${output_dir}/${train_model}/${decode_prefix}.pixel.sorted.tsv.gz\n</code></pre></p> <p>Command: <pre><code>$neda_dir/steps/step4.1-pixel-level-decode.sh $input_configfile\n</code></pre></p>"},{"location":"analysis/Seurat/step4-decode/#step-42-visualizing-pixel-level-decoding-and-generating-marker-gene-reports","title":"Step 4.2 Visualizing Pixel-Level Decoding and Generating Marker Gene Reports","text":"<p>Identifying marker genes for each factor/cluster, and generating a report html file that summarizes individual factors and marker genes. In addition, this step creates a high-resolution image of cell type factors for individual pixels, using the color table generated at step 3.2.</p> <p>Input &amp; Output <pre><code>#Input:\n${output_dir}/${train_model}/${decode_prefix}.posterior.count.tsv.gz\n${output_dir}/${train_model}/${tranform_prefix}.rgb.tsv\n\n#Output: \n${output_dir}/${train_model}/${decode_prefix}.bulk_chisq.tsv\n${output_dir}/${train_model}/${decode_prefix}.factor.info.html\n${output_dir}/${train_model}/${decode_prefix}.pixel.png\n</code></pre></p> <p>Command: <pre><code>$neda_dir/steps/step4.2-pixel-level-visualization-and-report.sh $input_configfile\n</code></pre></p>"},{"location":"home/documentation_overview/","title":"Documentation Overview","text":"<p>The current documentation of NovaScope Exemplary Downstream Analysis (NEDA)  include the following sections:</p> <ul> <li>Installation: Instructions on how to install NEDA and dependent software tools.</li> <li>Preparing Input:<ul> <li>Input Data: Accessing the example input spatial digital gene expression matrix datasets.</li> <li>Job Configuration: Preparing the input configuration file.</li> </ul> </li> <li>Starting Downstream Analysis:<ul> <li>Introduction: A brief introduction of the step-by-step analytical procedures.</li> <li>Initializing: Initialize computing environment and data preprocessing</li> <li>Latent Dirichlet Allocation (LDA) + FICTURE Analysis: The step-by-step instruction for LDA and FICTURE analytical strategy.<ul> <li>LDA Factorization</li> <li>Transform</li> <li>Pixel-level Decoding:</li> </ul> </li> <li>Seurat + FICTURE Analysis: A step-by-step guideline for the analytical strategy using Seurat and FICTURE.<ul> <li>Seurat Clustering</li> <li>Transform</li> <li>Pixel-level Decoding</li> </ul> </li> </ul> </li> </ul>"},{"location":"installation/installation/","title":"Installation","text":""},{"location":"installation/installation/#1-install-the-novascope-exemplary-downstream-analysis-neda","title":"1. Install the NovaScope-exemplary-downstream-analysis (NEDA)","text":"<pre><code>git clone git@github.com:seqscope/NovaScope-exemplary-downstream-analysis.git \n</code></pre>"},{"location":"installation/installation/#2-install-softwares-and-dependencies","title":"2. Install Softwares and Dependencies","text":""},{"location":"installation/installation/#21-install-dependent-softwares","title":"2.1 Install Dependent Softwares","text":"<p>Ensure the installation of the below software to facilitate analysis. The versions listed below have been confirmed for compatibility with NovaScope-exemplary-downstream-analysis (NEDA) while alternative versions may also work with it.</p> <p>High-performance computing (HPC) users can easily load these programs using the <code>module load</code> command. It's advisable to first check availability with <code>module available</code> or <code>module spider</code>.</p> <ul> <li>Samtools (v1.14)</li> <li>Python (v3.10) </li> <li>R (v4.2)</li> </ul>"},{"location":"installation/installation/#22-install-ficture-and-its-dependencies","title":"2.2 Install FICTURE and Its Dependencies","text":""},{"location":"installation/installation/#221-install-ficture","title":"2.2.1 Install FICTURE","text":"<p>To install FICTURE, run:</p> <pre><code>## revise the path to install ficture if needed\ngit clone git@github.com:seqscope/ficture.git\n</code></pre>"},{"location":"installation/installation/#222-reference-files","title":"2.2.2 Reference Files","text":"<p>FICTURE requires a reference file for the species of interest, which offers the gene type information, to filter the input genes. Currently, FICTURE provided such reference file for human and mouse:</p> <ul> <li>human: <ul> <li>GRCh38: <code>Homo_sapiens.GRCh38.107.names.tsv.gz</code></li> </ul> </li> <li>mouse: <ul> <li>GRCm39 (recommand): <code>Mus_musculus.GRCm39.107.names.tsv.gz</code></li> <li>GRCm38: <code>Mus_musculus.GRCm38.102.names.tsv.gz</code></li> </ul> </li> </ul> <p>Once you installed FICTURE, view available reference files:</p> <pre><code>## revise the path of ficture if you install ficture \nficture_dir=/path/to/ficture\n\n## double-check available reference files\nls -hlt $ficture_dir/info\n</code></pre>"},{"location":"installation/installation/#223-create-a-python-environment","title":"2.2.3 Create a Python Environment","text":"<p>Set up a Python environment for FICTURE as per the requirement file. The requirement file is included in the FICTURE repository.</p> <p>First, ensure the requirements file is accessible:</p> <pre><code>## path to the requirement file in the ficture repository\nficture_reqfile=$ficture_dir/requirements.txt\n\n## verify the existence of the requirement file.\nif [ -f \"$ficture_reqfile\" ]; then\n    echo -e \"The requirement file for FICTURE exists.\"\nelse\n    echo -e \"Error: The requirement file for FICTURE does not exist.\\n\"\n    echo -e \"Now downloading such requirement file...\"\n    curl -o $ficture_reqfile https://raw.githubusercontent.com/seqscope/ficture/8ceb419618c1181bb673255427b53198c4887cfa/requirements.txt\nfi\n</code></pre> <p>Now, install the required packages. Below is an example of creating a new Python environment using <code>venv</code>. It's also possible to establish such environments through alternative methods, including <code>conda</code>, <code>virtualenv</code>, and <code>pyenv</code>.</p> <pre><code>## set the path to the python virtual environment directory\npyenv_dir=/path/to/python/virtual/environment/directory\npyenv_name=name_of_python_venv\n\n## create the python virtual environment (need to be done only once)\nmkdir -p ${pyenv_dir}\ncd ${pyenv_dir}\npython -m venv ${pyenv_name}\n\n## activate the python environment (every time you want to use the environment)\nsource ${pyenv_name}/bin/activate\n\n## install the required packages (need to be done only once)\npip install -r $$ficture_reqfile\n</code></pre>"},{"location":"installation/installation/#23-install-r-packages","title":"2.3 Install R Packages","text":"<p>To enable Seurat analysis, install the following required R packages:</p> <ul> <li>Seurat</li> <li>ggplot2</li> <li>patchwork</li> <li>dplyr</li> <li>tidyverse</li> <li>stringr</li> <li>cowplot</li> <li>optparse</li> <li>RColorBrewer</li> </ul> <pre><code>## install all required packages in R\ninstall.packages(c( \"Seurat\", \"optparse\", \"patchwork\", \"dplyr\", \"tidyverse\", \"stringr\", \n                    \"ggplot2\", \"cowplot\", \"RColorBrewer\"))\n</code></pre>"},{"location":"prep_input/access_data/","title":"Accessing Example Datasets","text":""},{"location":"prep_input/access_data/#data-overview","title":"Data Overview","text":"<p>We provided three spatial digital gene expression (SGE) matrix datasets, published with the NovaScope protocol. Each SGE dataset could serve serves as the input data for the NovaScope-exemplary-downstream-analysis (NEDA).</p> <p>Those three SGE datasets were created via NovaScope utilizing FASTQ files derived from the same liver tissue section of an 8-week-old C57BL/6 wild-type male mouse. For more information on the original source FASTQ files used to create these SGE datasets, consult the NovaScope tutorial available here.</p>"},{"location":"prep_input/access_data/#minimal-test-run-spatial-digital-gene-expression-sge-dataset","title":"Minimal Test Run Spatial Digital Gene Expression (SGE) Dataset","text":"<p>The minimal test run SGE dataset was created using a subset of liver section with a relatively shallow depth in the 2nd sequencing. This dataset is intended for preliminary testing of NEDA, primarily for validating NEDA scripts' functionality. It is not designed to yield biological insights.</p>"},{"location":"prep_input/access_data/#shallow-liver-section-sge-dataset","title":"Shallow Liver Section SGE Dataset","text":"<p>This SGE dataset was generated by a Seq-Scope dataset for a tissue section, characterized by a relatively shallow 2nd-Seq library sequencing depth (i.e., approximately 163 million paired-end reads). The SGE dataset from FASTQ files with such depth should be sufficient to investigate major cell types alongside marker genes pertaining to liver cell diversity, and perform basic pixel-level decoding of the spatial transcriptome. This dataset comes along with a set of aligned Hematoxylin and Eosin (H&amp;E) stained histology images. </p>"},{"location":"prep_input/access_data/#deep-liver-section-sge-dataset","title":"Deep Liver Section SGE Dataset","text":"<p>The initial examination of the shallow SGE dataset was encouraging, prompting a more extensive sequencing of the sample tissue to fully saturate the library (i.e., approximately 2.61 billion paired-end reads). The deep SGE dataset was produced using all pairs of 2nd-seq FASTQ file. While datasets with shallower sequencing depths offer valuable insights, deep sequencing allows for a more thorough exploration of the data. This dataset also include a set of aligned H&amp;E stained histology images. </p>"},{"location":"prep_input/access_data/#data-format","title":"Data Format","text":""},{"location":"prep_input/access_data/#sge-dataset","title":"SGE Dataset","text":"<p>Each SGE dataset is composed of <code>features.tsv.gz</code>, <code>barcodes.tsv.gz</code>, and <code>matrix.mtx.gz</code>. The data format for an SGE dataset is demonstrated in NovaScope tutorial.</p> <p>For each SGE dataset, We also provided two additional figures:</p> <ul> <li><code>*.gene_full_mito.png</code>: This image displays the distribution of spatial barcodes that aligns to the reference genome.</li> <li><code>*.sge_match_sbcd.png</code>: This file presents three images side-by-side for a comprehensive view:<ul> <li>The spatial barcode (sbcd) image, showcasing the spatial barcode distribution along with fiducial markers, as detailed in Figure 11 of the NovaScope protocol paper.</li> <li>The smatch image, depicting the distribution of spatial barcodes that correspond to the 2nd-seq FASTQ files, referenced in Figure 12 of the NovaScope protocol paper.</li> <li>The SGE image, specifically referred to as <code>*.gene_full_mito.png</code>, as seen in Figure 13 of the NovaScope protocol paper.</li> </ul> </li> </ul>"},{"location":"prep_input/access_data/#aligned-hematoxylin-and-eosin-he-stained-histology-images","title":"Aligned Hematoxylin and Eosin (H&amp;E) Stained Histology Images","text":"<p>Both the shallow SGE dataset and the deep SGE dataset come alongside a set of aligned Hematoxylin and Eosin (H&amp;E) stained histology images. The aligned H&amp;E histology images were created by aligning the raw histology image to the spatial coordinates of the SGE matrix using the matching fiducial markers in both. </p> <p>Each set includes two aligned H&amp;E histology images:</p> <ul> <li><code>*-hne.tif</code>: A referenced geotiff file that allows the coordinate transformation between the SGE matrix and histology image.</li> <li><code>*-hne-fit.tif</code>: A tiff file that has the exact same dimension as the <code>*.sge_match_sbcd.png</code> and <code>*.gene_full_mito.png</code>.</li> </ul>"},{"location":"prep_input/access_data/#downloading-the-datasets","title":"Downloading the Datasets","text":"<p>Each of the three SGE datasets is available as a separate tarball file, all under a single DOI, accessible via this URL: https://doi.org/10.5281/zenodo.10841778</p> <ul> <li>Minimal Test Run SGE Dataset : </li> </ul> <pre><code>## To download the tarball from Zenodo, you can use the following command\ncurl -o B08Csub_20240319_SGE.tar.gz https://zenodo.org/records/10841778/files/B08Csub_20240319_SGE.tar.gz?download=1\n\n## (Optional) Verify the integrity of the tarball file\ncurl -o B08Csub_20240319_SGE.tar.gz.md5 https://zenodo.org/records/10841778/files/B08Csub_20240319_SGE.tar.gz.md5?download=1\nmd5sum -c B08Csub_20240319_SGE.tar.gz.md5\n\n## uncompress the tarball using the following command\ntar -zxvf B08Csub_20240319_SGE.tar.gz\n</code></pre> <ul> <li>Shallow Liver Section SGE Dataset:</li> </ul> <pre><code>## To download the tarball from Zenodo, you can use the following command\ncurl -o B08Cshallow_20240319_SGE_withHE.tar.gz https://zenodo.org/records/10841778/files/B08Cshallow_20240319_SGE_withHE.tar.gz?download=1\n\n## (Optional) Verify the integrity of the tarball file\ncurl -o B08Cshallow_20240319_SGE_withHE.tar.gz.md5 https://zenodo.org/records/10841778/files/B08Cshallow_20240319_SGE_withHE.tar.gz.md5?download=1\nmd5sum -c B08Cshallow_20240319_SGE_withHE.tar.gz.md5\n\n## uncompress the tarball using the following command\n## \ntar -zxvf B08Cshallow_20240319_SGE_withHE.tar.gz\n</code></pre> <ul> <li>Deep Liver Section SGE Dataset:</li> </ul> <pre><code>## Download the file\ncurl -o B08Cdeep_20240319_SGE_withHE.tar.gz https://zenodo.org/records/10841778/files/B08Cdeep_20240319_SGE_withHE.tar.gz?download=1\n\n## (Optional) Check the integrity\ncurl -o B08Cdeep_20240319_SGE_withHE.tar.gz.md5 https://zenodo.org/records/10841778/files/B08Cdeep_20240319_SGE_withHE.tar.gz.md5?download=1\nmd5sum -c B08Cdeep_20240319_SGE_withHE.tar.gz.md5\n\n## Extraction\ntar -zxvf B08Cdeep_20240319_SGE_withHE.tar.gz\n</code></pre>"},{"location":"prep_input/job_config/","title":"Preparing the Input Configuration File","text":"<p>The input configuration file, which is a text file, serves as the input for parameters and dataset paths. We provide an example configuration file for LDA+FICTURE analysis and Seurat+FICTURE analysis, separately. </p> <p>Below only include FICTURE's essential parameters, while certain steps might need auxiliary parameters. In such cases, NEDA employs FICTURE's recommended defaults for these extra settings, wherever applicable. Should you wish to customize these auxiliary parameters beyond the defaults, please proceed with caution as it involves risk. For detailed information on modifying auxiliary parameters, kindly refer to the <code>AUXILIARY PARAMS</code> section in the script for each respective step and original publication of FICTURE.</p> <pre><code>## Environment Paths\npy_env=&lt;path_to_the_python_environment&gt;                             ## path to Python environment \nficture=&lt;path_to_the_ficture_repository&gt;                            ## path to FICTURE repository\nref_geneinfo=&lt;path_to_the_reference_dataset&gt;                        ## path to the reference file, please make sure\n\n## Input/Output \ninput_dir=&lt;path_to_the_input_directory&gt;                             ## Directory for input files\noutput_dir=&lt;path_to_the_output_directory&gt;                           ## Directory for output files: LDA results saved in ${output_dir}/LDA, and Seurat results in ${output_dir}/Seurat.\"\nprefix=&lt;prefix_of_output_files&gt;                                     ## Prefix for output files. The output files will be named using both this prefix and the following analytical parameters.\n\n## Analytical Parameters\ntrain_model=&lt;model_option&gt;                                          ## Define the analytical strategy. Options: \"LDA\", \"Seurat\".\n\nsf=&lt;solo_feature&gt;                                                   ## Feature selection, e.g., \"gn\", which is short for \"gene\".\ntw=&lt;train_width&gt;                                                    ## The side length of the hexagon (in micrometers), e.g., 18.\nnf=&lt;number_of_factors&gt;                                              ## (LDA-only) Number of factors, e.g., 12. For the 'Seurat + FICTURE' analysis, remove this line when preparing the configuration file; nf is defined after clustering.\nep=&lt;number_of_epoch&gt;                                                ## (LDA-only) Epochs for LDA training, e.g., 3. For \"Seurat+FICTURE\" analysis, use \"NA\".\npw=&lt;projection_width&gt;                                               ## Projection width, suggest to use one the same as the train width, e.g., 18.\nar=&lt;archor_distance&gt;                                                ## Anchor point distance (in micrometers), e.g., 4.\n\nseed=&lt;an_integer&gt;                                                   ## (Optional) A seed (integer, e.g., 2024030700) for reproducibility. This applies in the LDA factorization and choosing color maps. If omitted, a random seed will be utilized.\n\nmajor_axis=&lt;X_or_Y&gt;                                                 ## Generally, we defined the one with greater length as the major axis. Options: \"X\", \"Y\".\n</code></pre>"}]}